{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modeling Traffic Patterns for Given Dimensions\n",
    "\n",
    "For example,\n",
    "* How many cars travel this road on a given day?\n",
    "* Which were the days that saw the highest traffic?\n",
    "* What were top 10 games when there was maximum traffic?\n",
    "* what's the average traffic like on a game day vs non-game day?\n",
    "\n",
    "Sample data has,\n",
    "* Dimensions = Date, Game Day, Opponent, Win/Loss...\n",
    "* Metrics = Traffic count\n",
    "\n",
    "__Learning Objective:__\n",
    "\n",
    "* Summarizing Data along Dimensions using Spark's PairRDD\n",
    "* Learn Spark PairRDD's operations like map, reduceByKey, sortBy, leftOuterJoin, combineByKey, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and get quick sense of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">TODO: Configure files path</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficPath = \"D:\\\\Tirthal-LABs\\\\xLocal-Git-Repo\\\\Learning-BigData\\\\gs-spark\\\\gs-spark-python\\\\notebooks\\\\03\\\\Dodgers.data\"\n",
    "gamesPath = \"D:\\\\Tirthal-LABs\\\\xLocal-Git-Repo\\\\Learning-BigData\\\\gs-spark\\\\gs-spark-python\\\\notebooks\\\\03\\\\Dodgers.events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4/10/2005 0:00,-1',\n",
       " '4/10/2005 0:05,-1',\n",
       " '4/10/2005 0:10,-1',\n",
       " '4/10/2005 0:15,-1',\n",
       " '4/10/2005 0:20,-1',\n",
       " '4/10/2005 0:25,-1',\n",
       " '4/10/2005 0:30,-1',\n",
       " '4/10/2005 0:35,-1',\n",
       " '4/10/2005 0:40,-1',\n",
       " '4/10/2005 0:45,-1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic = sc.textFile(trafficPath)\n",
    "traffic.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Traffic data analysis__ <br/>\n",
    "Column 1 = 5 minutes slice of time <br/>\n",
    "Column 2 = No of cars passed by in that 5 minutes slice window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04/12/05,13:10:00,16:23:00,55892,San Francisco,W 9-8�',\n",
       " '04/13/05,19:10:00,21:48:00,46514,San Francisco,W 4-1�',\n",
       " '04/15/05,19:40:00,21:48:00,51816,San Diego,W 4-0�',\n",
       " '04/16/05,19:10:00,21:52:00,54704,San Diego,W 8-3�',\n",
       " '04/17/05,13:10:00,15:31:00,53402,San Diego,W 6-0�',\n",
       " '04/25/05,19:10:00,21:33:00,36876,Arizona,L 4-2�',\n",
       " '04/26/05,19:10:00,22:00:00,44486,Arizona,L 3-2�',\n",
       " '04/27/05,19:10:00,22:17:00,54387,Arizona,L 6-3�',\n",
       " '04/29/05,19:40:00,22:01:00,40150,Colorado,W 6-3�',\n",
       " '04/30/05,19:10:00,21:45:00,54123,Colorado,W 6-2�']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games = sc.textFile(gamesPath)\n",
    "games.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Events data analysis__ <br/>\n",
    "Column 1 and 2 = Start and End time of Game <br/>\n",
    "Column 3 = Audience count <br/>\n",
    "Column 4 = Opponent <br/>\n",
    "Column 5 = Win/Loss score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a PairRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "def parseTraffic(row):\n",
    "    DATE_FMT = \"%m/%d/%Y %H:%M\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],DATE_FMT)\n",
    "    row[1] = int(row[1])\n",
    "    return (row[0],row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficParsed = traffic.map(parseTraffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2005, 4, 10, 0, 0), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 5), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 10), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 15), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 20), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 25), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 30), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 35), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 40), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 45), -1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficParsed.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing a Pair RDD using reduceByKey\n",
    "\n",
    "reduceByKey = Combine records with the same key in a specified way e.g. sum, maximum, minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Computing daily traffic trends__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement = what's traffic by date?\n",
    "# Extract date from timestamp\n",
    "dailyTrend = trafficParsed.map(lambda x: (x[0].date(),x[1]))\\\n",
    "                        .reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 10), -288),\n",
       " (datetime.date(2005, 4, 11), 5062),\n",
       " (datetime.date(2005, 4, 14), 6423),\n",
       " (datetime.date(2005, 4, 15), 6459),\n",
       " (datetime.date(2005, 4, 16), 6002),\n",
       " (datetime.date(2005, 4, 17), 5322),\n",
       " (datetime.date(2005, 4, 18), 5600),\n",
       " (datetime.date(2005, 4, 19), 6049),\n",
       " (datetime.date(2005, 4, 21), 5977),\n",
       " (datetime.date(2005, 4, 22), 6038)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrend.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 7, 28), 7661),\n",
       " (datetime.date(2005, 7, 29), 7499),\n",
       " (datetime.date(2005, 8, 12), 7287),\n",
       " (datetime.date(2005, 7, 27), 7238),\n",
       " (datetime.date(2005, 9, 23), 7175),\n",
       " (datetime.date(2005, 7, 26), 7163),\n",
       " (datetime.date(2005, 5, 20), 7119),\n",
       " (datetime.date(2005, 8, 11), 7110),\n",
       " (datetime.date(2005, 9, 8), 7107),\n",
       " (datetime.date(2005, 9, 7), 7082)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requirement = Find on which date, there was maximum amount of traffic?\n",
    "# Sort based on second element (-x[1] to specify descending order)\n",
    "dailyTrend.sortBy(lambda x:-x[1]).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Pair RDDs and Adding a Dimension to RDD using leftOuterJoin\n",
    "\n",
    "Merge two Pair RDDs based on keys\n",
    "* join (inner join) = values whose keys match are grouped together and a join returns a new Pair RDD\n",
    "* leftOuterJoin = all keys from the left RDD are returned\n",
    "* rightOuterJoin = all keys from the right RDD are returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merging with the games data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 12), 'San Francisco'),\n",
       " (datetime.date(2005, 4, 13), 'San Francisco'),\n",
       " (datetime.date(2005, 4, 15), 'San Diego'),\n",
       " (datetime.date(2005, 4, 16), 'San Diego'),\n",
       " (datetime.date(2005, 4, 17), 'San Diego'),\n",
       " (datetime.date(2005, 4, 25), 'Arizona'),\n",
       " (datetime.date(2005, 4, 26), 'Arizona'),\n",
       " (datetime.date(2005, 4, 27), 'Arizona'),\n",
       " (datetime.date(2005, 4, 29), 'Colorado'),\n",
       " (datetime.date(2005, 4, 30), 'Colorado')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requirement = What are top 10 game days when there was maximum traffic?\n",
    "\n",
    "# Both PairRDD must need same key, so need to create PairRDD with date as key for games\n",
    "def parseGames(row):\n",
    "    DATE_FMT = \"%m/%d/%y\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],DATE_FMT).date()\n",
    "    return (row[0],row[4])\n",
    "\n",
    "gamesParsed = games.map(parseGames)\n",
    "gamesParsed.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining with Games \n",
    "dailyTrendCombined = dailyTrend.leftOuterJoin(gamesParsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 11), (5062, None)),\n",
       " (datetime.date(2005, 4, 15), (6459, 'San Diego')),\n",
       " (datetime.date(2005, 4, 17), (5322, 'San Diego')),\n",
       " (datetime.date(2005, 4, 19), (6049, None)),\n",
       " (datetime.date(2005, 4, 21), (5977, None)),\n",
       " (datetime.date(2005, 4, 22), (6038, None)),\n",
       " (datetime.date(2005, 4, 23), (5366, None)),\n",
       " (datetime.date(2005, 4, 24), (4319, None)),\n",
       " (datetime.date(2005, 4, 25), (6280, 'Arizona')),\n",
       " (datetime.date(2005, 4, 30), (6090, 'Colorado'))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrendCombined.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right RDD value is None, which indicates that there was no game on that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take record and convert to tupple(Date, Opponenet, Type of Day, No of Cars)\n",
    "def checkGameDay(row):\n",
    "    if row[1][1] == None:\n",
    "        return (row[0],row[1][1],\"Regular Day\",row[1][0])\n",
    "    else:\n",
    "        return (row[0],row[1][1],\"Game Day\",row[1][0])\n",
    "    \n",
    "dailyTrendbyGames = dailyTrendCombined.map(checkGameDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 11), None, 'Regular Day', 5062),\n",
       " (datetime.date(2005, 4, 15), 'San Diego', 'Game Day', 6459),\n",
       " (datetime.date(2005, 4, 17), 'San Diego', 'Game Day', 5322),\n",
       " (datetime.date(2005, 4, 19), None, 'Regular Day', 6049),\n",
       " (datetime.date(2005, 4, 21), None, 'Regular Day', 5977),\n",
       " (datetime.date(2005, 4, 22), None, 'Regular Day', 6038),\n",
       " (datetime.date(2005, 4, 23), None, 'Regular Day', 5366),\n",
       " (datetime.date(2005, 4, 24), None, 'Regular Day', 4319),\n",
       " (datetime.date(2005, 4, 25), 'Arizona', 'Game Day', 6280),\n",
       " (datetime.date(2005, 4, 30), 'Colorado', 'Game Day', 6090)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrendbyGames.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 7, 28), 'Cincinnati', 'Game Day', 7661),\n",
       " (datetime.date(2005, 7, 29), 'St. Louis', 'Game Day', 7499),\n",
       " (datetime.date(2005, 8, 12), 'NY Mets', 'Game Day', 7287),\n",
       " (datetime.date(2005, 7, 27), 'Cincinnati', 'Game Day', 7238),\n",
       " (datetime.date(2005, 9, 23), 'Pittsburgh', 'Game Day', 7175),\n",
       " (datetime.date(2005, 7, 26), 'Cincinnati', 'Game Day', 7163),\n",
       " (datetime.date(2005, 5, 20), 'LA Angels', 'Game Day', 7119),\n",
       " (datetime.date(2005, 8, 11), 'Philadelphia', 'Game Day', 7110),\n",
       " (datetime.date(2005, 9, 8), None, 'Regular Day', 7107),\n",
       " (datetime.date(2005, 9, 7), 'San Francisco', 'Game Day', 7082)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by no of cars to see maximum traffic trends along with if there was Game or not on that day\n",
    "dailyTrendbyGames.sortBy(lambda x:-x[3]).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Averages with Pair RDDs using combineByKey\n",
    "\n",
    "combineByKey = combine records with the same key in a specified way (i.e. which gives very granular control over how the computation should happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Regular Day', 5411.329787234043), ('Game Day', 5948.604938271605)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requirement = Compare average traffic on Game Day vs Non Game day \n",
    "\n",
    "dailyTrendbyGames.map(lambda x:(x[2],x[3]))\\\n",
    "                 .combineByKey(lambda value : (value,1),\\\n",
    "                      lambda acc,value:(acc[0]+value,acc[1]+1),\\\n",
    "                      lambda acc1,acc2:(acc1[0]+acc2[0],acc1[1]+acc2[1]))\\\n",
    "                 .mapValues(lambda x:x[0]/x[1])\\\n",
    "                 .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example code of the [pluralsight course](https://app.pluralsight.com/library/courses/apache-spark-beginning-data-exploration-analysis), which I just upgraded to work with Python 3.6 while learning Spark."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
